# ğŸ§  Code Explainer â€” AI-Powered Code Understanding Tool

The **Code Explainer** is an intelligent application that allows users to upload their source code (or zip folders), automatically index it using **LangChain**, and then **chat with their code** to understand its logic, structure, and behavior â€” just like having an AI code reviewer or mentor.

This project uses **OpenRouter (or OpenAI)** models integrated with **LangChain**, **Chroma vector database**, and **Streamlit** for an interactive UI.

---

## ğŸš€ Features

- ğŸ“‚ **Upload Files or Folders**
  - Supports `.py`, `.js`, `.cpp`, `.c`, `.h`, and `.txt` files
  - Accepts both single files and zipped projects

- ğŸ§© **Automatic Code Indexing**
  - Splits code into manageable chunks
  - Creates vector embeddings using `OpenAIEmbeddings`
  - Stores them in a **ChromaDB** vector store for efficient retrieval

- ğŸ’¬ **Chat with Your Code**
  - Asks questions like:
    > â€œWhat does this function do?â€  
    > â€œHow are database connections handled?â€  
    > â€œWhich part of the code initializes the API?â€

- ğŸ”„ **Memory-Aware Conversations**
  - Remembers previous context using `ConversationBufferMemory`
  - Provides smoother, contextual follow-up answers

- ğŸŒ **Supports OpenRouter API**
  - Compatible with OpenAI or OpenRouter endpoints  
  - Default model: `gpt-4o-mini`

---

## ğŸ§  Tech Stack

| Component | Technology Used | Purpose |
|------------|----------------|----------|
| **Frontend/UI** | Streamlit | User interface for file upload and chat |
| **Backend Engine** | Python | Core logic, model integration, and data handling |
| **LLM Framework** | LangChain | Handles retrieval, memory, and chain orchestration |
| **Model Provider** | OpenRouter / OpenAI | Provides the language model for explanations |
| **Embeddings** | OpenAIEmbeddings | Converts text into numerical vectors |
| **Vector Database** | ChromaDB | Stores and retrieves semantically similar code chunks |
| **Environment Management** | Python-dotenv | Loads environment variables securely |

---

## âš™ï¸ Project Flow (Architecture Overview)

Below is the high-level architecture of how **Code Explainer** works end-to-end:

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚        User Uploads        â”‚
         â”‚ .py / .js / .cpp / .zip    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      File Handling       â”‚
          â”‚ utils/loader.py          â”‚
          â”‚ â†’ Save file              â”‚
          â”‚ â†’ Extract zip (if any)   â”‚
          â”‚ â†’ Load text content      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚    Text Splitting        â”‚
          â”‚ utils/vectorstore.py     â”‚
          â”‚ â†’ Split into chunks      â”‚
          â”‚ â†’ Create embeddings      â”‚
          â”‚ â†’ Store in ChromaDB      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Conversational Chain     â”‚
          â”‚ utils/llm_chain.py       â”‚
          â”‚ â†’ ChatOpenAI model       â”‚
          â”‚ â†’ Memory via LangChain   â”‚
          â”‚ â†’ Retrieval mechanism    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚         Streamlit UI       â”‚
         â”‚  app.py                    â”‚
         â”‚ â†’ Ask questions            â”‚
         â”‚ â†’ Retrieve code context    â”‚
         â”‚ â†’ Display AI explanations  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


**Summary of Flow:**
1. User uploads source code or zip â†’ handled by `loader.py`.
2. Code is split into chunks â†’ embedded using `OpenAIEmbeddings`.
3. Embeddings stored in **ChromaDB**.
4. When a user asks a question:
   - Retriever fetches relevant code snippets.
   - LLM (`ChatOpenAI`) analyzes them.
   - Response is generated with context and memory.
5. Streamlit displays results interactively.

---


